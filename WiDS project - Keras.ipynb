{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                image_id  has_oilpalm   score\n",
      "0      img_000002017.jpg            0  0.7895\n",
      "1      img_000012017.jpg            0  1.0000\n",
      "2      img_000022017.jpg            0  1.0000\n",
      "3      img_000072017.jpg            0  1.0000\n",
      "4      img_000082017.jpg            0  1.0000\n",
      "5      img_000092017.jpg            0  1.0000\n",
      "6      img_000102017.jpg            0  1.0000\n",
      "7      img_000112017.jpg            0  0.8352\n",
      "8      img_000132017.jpg            0  1.0000\n",
      "9      img_000142017.jpg            0  1.0000\n",
      "10     img_000152017.jpg            0  1.0000\n",
      "11     img_000172017.jpg            0  1.0000\n",
      "12     img_000192017.jpg            0  1.0000\n",
      "13     img_000202017.jpg            0  1.0000\n",
      "14     img_000212017.jpg            0  1.0000\n",
      "15     img_000232017.jpg            0  1.0000\n",
      "16     img_000242017.jpg            0  1.0000\n",
      "17     img_000252017.jpg            0  1.0000\n",
      "18     img_000272017.jpg            0  1.0000\n",
      "19     img_000282017.jpg            0  1.0000\n",
      "20     img_000302017.jpg            0  0.7730\n",
      "21     img_000312017.jpg            0  1.0000\n",
      "22     img_000322017.jpg            0  1.0000\n",
      "23     img_000332017.jpg            0  1.0000\n",
      "24     img_000342017.jpg            0  1.0000\n",
      "25     img_000352017.jpg            0  1.0000\n",
      "26     img_000362017.jpg            0  1.0000\n",
      "27     img_000372017.jpg            0  1.0000\n",
      "28     img_000392017.jpg            0  1.0000\n",
      "29     img_000402017.jpg            0  0.7745\n",
      "...                  ...          ...     ...\n",
      "15214  img_112242018.jpg            0  1.0000\n",
      "15215  img_112252018.jpg            0  1.0000\n",
      "15216  img_112272018.jpg            0  0.8112\n",
      "15217  img_112292018.jpg            0  1.0000\n",
      "15218  img_112302018.jpg            0  1.0000\n",
      "15219  img_112312018.jpg            0  1.0000\n",
      "15220  img_112322018.jpg            0  1.0000\n",
      "15221  img_112332018.jpg            0  0.8292\n",
      "15222  img_112342018.jpg            1  1.0000\n",
      "15223  img_112352018.jpg            0  1.0000\n",
      "15224  img_112362018.jpg            0  0.6095\n",
      "15225  img_112372018.jpg            0  1.0000\n",
      "15226  img_112402018.jpg            0  0.6076\n",
      "15227  img_112412018.jpg            0  1.0000\n",
      "15228  img_112432018.jpg            0  0.7991\n",
      "15229  img_112442018.jpg            0  1.0000\n",
      "15230  img_112482018.jpg            0  1.0000\n",
      "15231  img_112492018.jpg            0  0.4104\n",
      "15232  img_112502018.jpg            0  1.0000\n",
      "15233  img_112512018.jpg            0  0.8006\n",
      "15234  img_112532018.jpg            0  1.0000\n",
      "15235  img_112542018.jpg            0  1.0000\n",
      "15236  img_112552018.jpg            0  1.0000\n",
      "15237  img_112562018.jpg            0  1.0000\n",
      "15238  img_112592018.jpg            0  1.0000\n",
      "15239  img_112602018.jpg            0  0.6093\n",
      "15240  img_112612018.jpg            0  1.0000\n",
      "15241  img_112622018.jpg            0  1.0000\n",
      "15242  img_112632018.jpg            0  1.0000\n",
      "15243  img_112642018.jpg            0  1.0000\n",
      "\n",
      "[15244 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_oilpalm</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15244.000000</td>\n",
       "      <td>15244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.061795</td>\n",
       "      <td>0.955769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.240790</td>\n",
       "      <td>0.109367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_oilpalm         score\n",
       "count  15244.000000  15244.000000\n",
       "mean       0.061795      0.955769\n",
       "std        0.240790      0.109367\n",
       "min        0.000000      0.388700\n",
       "25%        0.000000      1.000000\n",
       "50%        0.000000      1.000000\n",
       "75%        0.000000      1.000000\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('traininglabels.csv')\n",
    "sample_sub = pd.read_csv('SampleSubmission.csv')\n",
    "print(train)\n",
    "train.head()\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.has_oilpalm==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.has_oilpalm==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15244 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"./train\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2178 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "validation__generator = test_datagen.flow_from_directory(\n",
    "    directory=r'.\\valid',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4356 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=r'.\\test',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000004328439C18>\n"
     ]
    }
   ],
   "source": [
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\tmodel.add(Dense(8, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\tprint (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
